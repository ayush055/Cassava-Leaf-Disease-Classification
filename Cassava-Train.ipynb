{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:08.928569Z",
     "iopub.status.busy": "2021-02-16T04:22:08.927469Z",
     "iopub.status.idle": "2021-02-16T04:22:16.626773Z",
     "shell.execute_reply": "2021-02-16T04:22:16.627378Z"
    },
    "papermill": {
     "duration": 7.769676,
     "end_time": "2021-02-16T04:22:16.627791",
     "exception": false,
     "start_time": "2021-02-16T04:22:08.858115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import math, re, os, gc\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:17.240469Z",
     "iopub.status.busy": "2021-02-16T04:22:17.239453Z",
     "iopub.status.idle": "2021-02-16T04:22:18.601492Z",
     "shell.execute_reply": "2021-02-16T04:22:18.602055Z"
    },
    "papermill": {
     "duration": 1.426005,
     "end_time": "2021-02-16T04:22:18.602285",
     "exception": false,
     "start_time": "2021-02-16T04:22:17.17628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "user_credential = user_secrets.get_gcloud_credential()\n",
    "user_secrets.set_tensorflow_credential(user_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:18.849363Z",
     "iopub.status.busy": "2021-02-16T04:22:18.848407Z",
     "iopub.status.idle": "2021-02-16T04:22:24.14326Z",
     "shell.execute_reply": "2021-02-16T04:22:24.142482Z"
    },
    "papermill": {
     "duration": 5.357558,
     "end_time": "2021-02-16T04:22:24.14343",
     "exception": false,
     "start_time": "2021-02-16T04:22:18.785872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:24.526256Z",
     "iopub.status.busy": "2021-02-16T04:22:24.525491Z",
     "iopub.status.idle": "2021-02-16T04:22:24.928659Z",
     "shell.execute_reply": "2021-02-16T04:22:24.927943Z"
    },
    "papermill": {
     "duration": 0.472684,
     "end_time": "2021-02-16T04:22:24.928843",
     "exception": false,
     "start_time": "2021-02-16T04:22:24.456159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Variables\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "AUG_BATCH = BATCH_SIZE\n",
    "IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "\n",
    "\n",
    "FOLDS = 5\n",
    "SEED = 1\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:25.087676Z",
     "iopub.status.busy": "2021-02-16T04:22:25.08655Z",
     "iopub.status.idle": "2021-02-16T04:22:25.089831Z",
     "shell.execute_reply": "2021-02-16T04:22:25.090331Z"
    },
    "papermill": {
     "duration": 0.097707,
     "end_time": "2021-02-16T04:22:25.090528",
     "exception": false,
     "start_time": "2021-02-16T04:22:24.992821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Augmentation Definitions\n",
    "# https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "# https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "def transform(image,label):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = 15. * tf.random.normal([1],dtype='float32')\n",
    "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3]),label\n",
    "\n",
    "def cutmix(image, label, PROBABILITY = 1.0):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with cutmix applied\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    \n",
    "    imgs = []; labs = []\n",
    "    for j in range(AUG_BATCH):\n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n",
    "        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image[j,ya:yb,0:xa,:]\n",
    "        two = image[k,ya:yb,xa:xb,:]\n",
    "        three = image[j,ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n",
    "        imgs.append(img)\n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
    "        if len(label.shape)==1:\n",
    "            lab1 = tf.one_hot(label[j],len(CLASSES))\n",
    "            lab2 = tf.one_hot(label[k],len(CLASSES))\n",
    "        else:\n",
    "            lab1 = label[j,]\n",
    "            lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
    "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))        \n",
    "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,len(CLASSES)))\n",
    "    return image2,label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:25.226997Z",
     "iopub.status.busy": "2021-02-16T04:22:25.222309Z",
     "iopub.status.idle": "2021-02-16T04:22:25.230217Z",
     "shell.execute_reply": "2021-02-16T04:22:25.229481Z"
    },
    "papermill": {
     "duration": 0.08011,
     "end_time": "2021-02-16T04:22:25.230373",
     "exception": false,
     "start_time": "2021-02-16T04:22:25.150263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsai.net/p/machine-learning/building-complex-image-augmentation-pipelines-with-tensorflow-bed1914278d2\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n",
    "    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "#     p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "#     p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "#     if p_shear > .2:\n",
    "#         if p_shear > .6:\n",
    "#             image = transform_shear(image, HEIGHT, shear=20.)\n",
    "#         else:\n",
    "#             image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "#     if p_rotation > .2:\n",
    "#         if p_rotation > .6:\n",
    "#             image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "#         else:\n",
    "#             image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(512*.6), 512, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n",
    "    \n",
    "    image = tf.image.resize(image, size=[512, 512])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:25.900329Z",
     "iopub.status.busy": "2021-02-16T04:22:25.899278Z",
     "iopub.status.idle": "2021-02-16T04:22:25.920009Z",
     "shell.execute_reply": "2021-02-16T04:22:25.919354Z"
    },
    "papermill": {
     "duration": 0.082714,
     "end_time": "2021-02-16T04:22:25.920187",
     "exception": false,
     "start_time": "2021-02-16T04:22:25.837473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Processing Functions\n",
    "\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "# Test image does not have a label so if condition is required\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_name\" : tf.io.FixedLenFeature([], tf.string)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    image_name = example['image_name']\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        label = tf.one_hot(label, depth=len(CLASSES))\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(dataset, do_init_aug=True, do_aug=True, shuffleBuffer=2048):\n",
    "    \n",
    "    if do_init_aug:\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "        dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    if do_aug: \n",
    "        dataset = dataset.batch(AUG_BATCH)\n",
    "        dataset = dataset.map(cutmix, num_parallel_calls=AUTOTUNE)\n",
    "        dataset = dataset.unbatch()\n",
    "    dataset = dataset.shuffle(shuffleBuffer)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(dataset, ordered=False, do_aug=False):\n",
    "    if do_aug:\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "        dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def countItems(dataset):\n",
    "    count = 0\n",
    "    for item in dataset:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:26.326518Z",
     "iopub.status.busy": "2021-02-16T04:22:26.325582Z",
     "iopub.status.idle": "2021-02-16T04:22:27.134297Z",
     "shell.execute_reply": "2021-02-16T04:22:27.133624Z"
    },
    "papermill": {
     "duration": 0.880158,
     "end_time": "2021-02-16T04:22:27.134465",
     "exception": false,
     "start_time": "2021-02-16T04:22:26.254307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MY_DATA_PATH=KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')\n",
    "MY_DATA_PATH = MY_DATA_PATH + \"/train_tfrecords/*.tfrec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:27.261677Z",
     "iopub.status.busy": "2021-02-16T04:22:27.260929Z",
     "iopub.status.idle": "2021-02-16T04:22:27.344155Z",
     "shell.execute_reply": "2021-02-16T04:22:27.343273Z"
    },
    "papermill": {
     "duration": 0.151362,
     "end_time": "2021-02-16T04:22:27.344321",
     "exception": false,
     "start_time": "2021-02-16T04:22:27.192959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1 - Read filenames for tfrecords\n",
    "\n",
    "train_tfrecords_names = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/cassava-leaf-disease-classification/train_tfrecords/'):\n",
    "    for filename in filenames:\n",
    "        train_tfrecords_names.append(os.path.join(dirname, filename))\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(MY_DATA_PATH)\n",
    "\n",
    "# TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:27.470178Z",
     "iopub.status.busy": "2021-02-16T04:22:27.469429Z",
     "iopub.status.idle": "2021-02-16T04:22:27.473991Z",
     "shell.execute_reply": "2021-02-16T04:22:27.473428Z"
    },
    "papermill": {
     "duration": 0.071546,
     "end_time": "2021-02-16T04:22:27.474154",
     "exception": false,
     "start_time": "2021-02-16T04:22:27.402608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TRAINING_IMAGES = int(count_data_items(TRAINING_FILENAMES) * (FOLDS-1.)/FOLDS) # + count_data_items(TRAINING_EXTERNAL_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = int(count_data_items(TRAINING_FILENAMES) * (1./FOLDS))\n",
    "# NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "\n",
    "print('Dataset: {} training images, {} validation images, unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063025,
     "end_time": "2021-02-16T04:22:28.660239",
     "exception": false,
     "start_time": "2021-02-16T04:22:28.597214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:28.944104Z",
     "iopub.status.busy": "2021-02-16T04:22:28.92417Z",
     "iopub.status.idle": "2021-02-16T04:22:39.06458Z",
     "shell.execute_reply": "2021-02-16T04:22:39.063953Z"
    },
    "papermill": {
     "duration": 10.209229,
     "end_time": "2021-02-16T04:22:39.064906",
     "exception": false,
     "start_time": "2021-02-16T04:22:28.855677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U efficientnet\n",
    "from keras import applications\n",
    "import efficientnet.keras as efn\n",
    "from efficientnet.keras import EfficientNetB3\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:39.210049Z",
     "iopub.status.busy": "2021-02-16T04:22:39.209076Z",
     "iopub.status.idle": "2021-02-16T04:22:42.465888Z",
     "shell.execute_reply": "2021-02-16T04:22:42.465028Z"
    },
    "papermill": {
     "duration": 3.337185,
     "end_time": "2021-02-16T04:22:42.466043",
     "exception": false,
     "start_time": "2021-02-16T04:22:39.128858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.system('pip install ../input/tf2cvmodels/TensorFlow-ResNets-master/ -q --no-deps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:42.59665Z",
     "iopub.status.busy": "2021-02-16T04:22:42.595945Z",
     "iopub.status.idle": "2021-02-16T04:22:42.607881Z",
     "shell.execute_reply": "2021-02-16T04:22:42.607191Z"
    },
    "papermill": {
     "duration": 0.079617,
     "end_time": "2021-02-16T04:22:42.608038",
     "exception": false,
     "start_time": "2021-02-16T04:22:42.528421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tf2_resnets import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:42.882752Z",
     "iopub.status.busy": "2021-02-16T04:22:42.877111Z",
     "iopub.status.idle": "2021-02-16T04:22:42.904421Z",
     "shell.execute_reply": "2021-02-16T04:22:42.903779Z"
    },
    "papermill": {
     "duration": 0.095002,
     "end_time": "2021-02-16T04:22:42.904579",
     "exception": false,
     "start_time": "2021-02-16T04:22:42.809577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CategoricalFocalLossLabelSmoothing(tf.keras.losses.Loss):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, ls=0.1, classes=5.0):\n",
    "        super(CategoricalFocalLossLabelSmoothing, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.ls = ls\n",
    "        self.classes = classes\n",
    "        \n",
    "    def focal_loss(self, y_true, y_pred, gamma, alpha, ls, classes):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        #y_pred = y_pred + epsilon\n",
    "        #label smoothing\n",
    "        y_pred_ls = (1 - ls) * y_pred + ls / classes\n",
    "        # Clip the prediction value\n",
    "        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true*K.log(y_pred_ls)\n",
    "        # Calculate weight that consists of  modulating factor and weighting factor\n",
    "        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        return self.focal_loss(y_true, y_pred, gamma=self.gamma, alpha=self.alpha, ls=self.ls, classes=self.classes)\n",
    "\n",
    "class TaylorCrossEntropyLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, n=3, label_smoothing=0.0):\n",
    "        super(TaylorCrossEntropyLoss, self).__init__()\n",
    "        self.n = n\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "    def taylor_cross_entropy_loss(self, y_pred, y_true, n=3, label_smoothing=0.0):\n",
    "        \"\"\"Taylor Cross Entropy Loss.\n",
    "        Args:\n",
    "        y_pred: A multi-dimensional probability tensor with last dimension `num_classes`.\n",
    "        y_true: A tensor with shape and dtype as y_pred.\n",
    "        n: An order of taylor expansion.\n",
    "        label_smoothing: A float in [0, 1] for label smoothing.\n",
    "        Returns:\n",
    "        A loss tensor.\n",
    "        \"\"\"\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        if label_smoothing > 0.0:\n",
    "            num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n",
    "            y_true = (1 - num_classes /(num_classes - 1) * label_smoothing) * y_true + label_smoothing / (num_classes - 1)\n",
    "\n",
    "        y_pred_n_order = tf.math.maximum(tf.stack([1 - y_pred] * n), 1e-7) # avoide being too small value\n",
    "        numerator = tf.math.maximum(tf.math.cumprod(y_pred_n_order, axis=0), 1e-7) # avoide being too small value\n",
    "        denominator = tf.expand_dims(tf.expand_dims(tf.range(1, n+1, dtype=\"float32\"), axis=1), axis=1)\n",
    "        y_pred_taylor = tf.math.maximum(tf.math.reduce_sum(tf.math.divide(numerator, denominator), axis=0), 1e-7) # avoide being too small value\n",
    "        loss_values = tf.math.reduce_sum(y_true * y_pred_taylor, axis=1, keepdims=True)\n",
    "        return tf.math.reduce_sum(loss_values, -1)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return self.taylor_cross_entropy_loss(y_pred, y_true, n=self.n, label_smoothing=self.label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:43.04996Z",
     "iopub.status.busy": "2021-02-16T04:22:43.048655Z",
     "iopub.status.idle": "2021-02-16T04:22:43.052231Z",
     "shell.execute_reply": "2021-02-16T04:22:43.051551Z"
    },
    "papermill": {
     "duration": 0.080621,
     "end_time": "2021-02-16T04:22:43.05238",
     "exception": false,
     "start_time": "2021-02-16T04:22:42.971759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "\n",
    "def get_model():\n",
    "    with strategy.scope():\n",
    "\n",
    "        efficient_net = EfficientNetB3(\n",
    "        weights='noisy-student',\n",
    "        input_shape=(512,512,3),\n",
    "        include_top=False\n",
    "    )\n",
    "        model = Sequential()\n",
    "        model.add(efficient_net)\n",
    "        model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units = len(CLASSES), activation='softmax'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "        loss = CategoricalFocalLossLabelSmoothing(gamma=2.0, alpha=0.25, ls=0.3, classes=5.0),\n",
    "        metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:43.192117Z",
     "iopub.status.busy": "2021-02-16T04:22:43.191404Z",
     "iopub.status.idle": "2021-02-16T04:22:43.194846Z",
     "shell.execute_reply": "2021-02-16T04:22:43.194117Z"
    },
    "papermill": {
     "duration": 0.076081,
     "end_time": "2021-02-16T04:22:43.194997",
     "exception": false,
     "start_time": "2021-02-16T04:22:43.118916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "\n",
    "def get_model2():\n",
    "    with strategy.scope():\n",
    "\n",
    "        resnet = models.ResNeSt101(\n",
    "        weights='imagenet',\n",
    "        input_shape=(512,512,3),\n",
    "        include_top=False\n",
    "    )\n",
    "        model = Sequential()\n",
    "        model.add(resnet)\n",
    "        model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units = len(CLASSES), activation='softmax'))\n",
    "        \n",
    "        model.summary()\n",
    "\n",
    "        model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:44.617347Z",
     "iopub.status.busy": "2021-02-16T04:22:44.616485Z",
     "iopub.status.idle": "2021-02-16T04:22:44.628896Z",
     "shell.execute_reply": "2021-02-16T04:22:44.629388Z"
    },
    "papermill": {
     "duration": 0.085511,
     "end_time": "2021-02-16T04:22:44.629576",
     "exception": false,
     "start_time": "2021-02-16T04:22:44.544065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_categorical_accuracy', factor = 0.3, \n",
    "                              patience = 2, min_delta = 0.001, \n",
    "                              mode = 'auto', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T04:22:47.637648Z",
     "iopub.status.busy": "2021-02-16T04:22:47.632229Z",
     "iopub.status.idle": "2021-02-16T09:08:36.955887Z",
     "shell.execute_reply": "2021-02-16T09:08:36.955265Z"
    },
    "papermill": {
     "duration": 17149.404447,
     "end_time": "2021-02-16T09:08:36.956062",
     "exception": false,
     "start_time": "2021-02-16T04:22:47.551615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "histories = []\n",
    "modelslist = []\n",
    "kfold = KFold(FOLDS, shuffle = True, random_state = SEED)\n",
    "FILENAMES = pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES})\n",
    "\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(TRAINING_FILENAMES)):\n",
    "    \n",
    "    model_save = tf.keras.callbacks.ModelCheckpoint('./model%i.h5'%fold,\n",
    "                             save_best_only = True, \n",
    "                             monitor = 'val_categorical_accuracy', \n",
    "                             mode = 'auto', verbose = 1)\n",
    "    \n",
    "    print(); print('#'*25)\n",
    "    print('### FOLD', fold+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    TRAIN_NAMES = list(FILENAMES.loc[trn_ind]['TRAINING_FILENAMES'])\n",
    "    train_dataset = load_dataset(TRAIN_NAMES, labeled = True)\n",
    "    val_dataset = load_dataset(FILENAMES.loc[val_ind]['TRAINING_FILENAMES'], labeled = True, ordered = True)\n",
    "    \n",
    "    model = get_model()\n",
    "    history = model.fit(\n",
    "        get_training_dataset(train_dataset, do_init_aug=True, do_aug=False, shuffleBuffer=NUM_TRAINING_IMAGES),\n",
    "        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "        epochs = 20,\n",
    "        callbacks=[model_save,\n",
    "                   reduce_lr,\n",
    "                  ],\n",
    "        validation_data = get_validation_dataset(val_dataset),\n",
    "        verbose=2\n",
    "    )\n",
    "    modelslist.append(model)\n",
    "    histories.append(history)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(len(model.history.history['categorical_accuracy'])),model.history.history['categorical_accuracy'],'-o',label='Train categorical_accuracy',color='#ff7f0e')\n",
    "    plt.plot(np.arange(len(model.history.history['categorical_accuracy'])),model.history.history['val_categorical_accuracy'],'-o',label='Val categorical_accuracy',color='#1f77b4')\n",
    "    x = np.argmax(model.history.history['val_categorical_accuracy'] ); y = np.max( model.history.history['val_categorical_accuracy'] )\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max categorical_accuracy\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('categorical_accuracy',size=14); plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(len(model.history.history['loss'])),model.history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(len(model.history.history['loss'])),model.history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin( model.history.history['val_loss'] ); y = np.min( model.history.history['val_loss'] )\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('Fold: %i | Image Size: %i | model: EfficientNetB%i |  Batch_size: %i'%(fold+1, 512, 7, 128))\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()\n",
    "    del model; gc.collect()\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "histories = []\n",
    "modelslist = []\n",
    "kfold = KFold(FOLDS, shuffle = True, random_state = SEED)\n",
    "FILENAMES = pd.DataFrame({'TRAINING_FILENAMES': TRAINING_FILENAMES})\n",
    "\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(TRAINING_FILENAMES)):\n",
    "    \n",
    "    model_save = tf.keras.callbacks.ModelCheckpoint('./resnetmodel%i.h5'%fold,\n",
    "                             save_best_only = True, \n",
    "                             monitor = 'val_categorical_accuracy', \n",
    "                             mode = 'auto', verbose = 1)\n",
    "    \n",
    "    print(); print('#'*25)\n",
    "    print('### FOLD', fold+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    TRAIN_NAMES = list(FILENAMES.loc[trn_ind]['TRAINING_FILENAMES'])\n",
    "    train_dataset = load_dataset(TRAIN_NAMES, labeled = True)\n",
    "    val_dataset = load_dataset(FILENAMES.loc[val_ind]['TRAINING_FILENAMES'], labeled = True, ordered = True)\n",
    "    \n",
    "    model = get_model2()\n",
    "    history = model.fit(\n",
    "        get_training_dataset(train_dataset, do_init_aug=True, do_aug=True, shuffleBuffer=NUM_TRAINING_IMAGES),\n",
    "        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks=[model_save,\n",
    "                   lr_callback\n",
    "                  ],\n",
    "        validation_data = get_validation_dataset(val_dataset),\n",
    "        verbose=2\n",
    "    )\n",
    "    modelslist.append(model)\n",
    "    histories.append(history)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(len(model.history.history['categorical_accuracy'])),model.history.history['categorical_accuracy'],'-o',label='Train categorical_accuracy',color='#ff7f0e')\n",
    "    plt.plot(np.arange(len(model.history.history['categorical_accuracy'])),model.history.history['val_categorical_accuracy'],'-o',label='Val categorical_accuracy',color='#1f77b4')\n",
    "    x = np.argmax(model.history.history['val_categorical_accuracy'] ); y = np.max( model.history.history['val_categorical_accuracy'] )\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max categorical_accuracy\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('categorical_accuracy',size=14); plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(len(model.history.history['loss'])),model.history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(len(model.history.history['loss'])),model.history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin( model.history.history['val_loss'] ); y = np.min( model.history.history['val_loss'] )\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('Fold: %i | Image Size: %i | model: EfficientNetB%i |  Batch_size: %i'%(fold+1, 512, 7, 128))\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()\n",
    "    del model; gc.collect()\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
