{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow.keras.backend as K\n",
    "from functools import partial\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('pip install /kaggle/input/kerasapplications -q')\n",
    "os.system('pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps')\n",
    "os.system('pip install ../input/tf2cvmodels/TensorFlow-ResNets-master/ -q --no-deps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2_resnets import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = [512, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "def transform(image):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = 15. * tf.random.normal([1],dtype='float32')\n",
    "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
    "    h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsai.net/p/machine-learning/building-complex-image-augmentation-pipelines-with-tensorflow-bed1914278d2\n",
    "\n",
    "def data_augment(image):\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "#     p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "#     p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "#     if p_shear > .2:\n",
    "#         if p_shear > .6:\n",
    "#             image = transform_shear(image, HEIGHT, shear=20.)\n",
    "#         else:\n",
    "#             image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "#     if p_rotation > .2:\n",
    "#         if p_rotation > .6:\n",
    "#             image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "#         else:\n",
    "#             image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(512*.6), 512, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[512, 512])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, RandomBrightness, HorizontalFlip, VerticalFlip, Flip, CenterCrop,\n",
    "    Rotate, ShiftScaleRotate, RandomResizedCrop)\n",
    "\n",
    "TTA1 = Compose([\n",
    "    HorizontalFlip(p=1)\n",
    "])\n",
    "\n",
    "TTA2 = Compose([\n",
    "    VerticalFlip(p=1)\n",
    "])\n",
    "\n",
    "TTA3 = Compose([\n",
    "    Flip(p=1),\n",
    "#     Rotate(limit=90, p=1)\n",
    "])\n",
    "\n",
    "TTA4 = Compose([\n",
    "#     Flip(p=1),\n",
    "#     HorizontalFlip(p=0.5),\n",
    "    CenterCrop(256, 256, p=1.0),\n",
    "#     ShiftScaleRotate(p=1),\n",
    "#     Rotate(limit=90, p=1)\n",
    "])\n",
    "\n",
    "TTA5 = Compose([\n",
    "#     Flip(p=1),\n",
    "#     HorizontalFlip(p=0.5),\n",
    "    RandomResizedCrop(512, 512, p=1),\n",
    "#     ShiftScaleRotate(p=1),\n",
    "#     Rotate(limit=90, p=1)\n",
    "])\n",
    "\n",
    "TTA6 = Compose([\n",
    "#     Flip(p=1),\n",
    "    HorizontalFlip(p=1),\n",
    "    CenterCrop(256, 256, p=1.0),\n",
    "    ShiftScaleRotate(p=1),\n",
    "#     Rotate(limit=90, p=1)\n",
    "])\n",
    "\n",
    "TTA7 = Compose([\n",
    "#     Flip(p=1),\n",
    "    HorizontalFlip(p=1),\n",
    "    RandomResizedCrop(512, 512, p=1),\n",
    "    ShiftScaleRotate(p=1),\n",
    "#     Rotate(limit=90, p=1)\n",
    "])\n",
    "\n",
    "TTA8 = Compose([\n",
    "    Rotate(limit=90, p=1)\n",
    "])\n",
    "\n",
    "TTA9 = Compose([\n",
    "    ShiftScaleRotate(p=1),\n",
    "])\n",
    "\n",
    "# TTA10 = Compose([\n",
    "# #     Flip(p=1),\n",
    "#     HorizontalFlip(p=0.5),\n",
    "#     RandomResizedCrop(512, 512, p=1),\n",
    "#     ShiftScaleRotate(p=1),\n",
    "# #     Rotate(limit=90, p=1)\n",
    "# ])\n",
    "\n",
    "# tta = [TTA1, TTA2, TTA3, TTA4, TTA5, TTA6, TTA7, TTA8, TTA9]\n",
    "tta = [TTA1, TTA2, TTA4, TTA5]\n",
    "# tta = [TTA1, TTA2, TTA3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.image.resize(img, (512, 512))\n",
    "    img = tf.reshape(img, [512, 512, 3])\n",
    "    return img\n",
    "\n",
    "def aug_fn(image, img_size, tta_num):\n",
    "    data = {\"image\":image}\n",
    "    aug_data = tta[tta_num](**data)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "#     aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "    return aug_img\n",
    "\n",
    "def process_data(image, img_size, tta_num):\n",
    "    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size, tta_num], Tout=tf.float32)\n",
    "    return aug_img\n",
    "\n",
    "def get_test_dataset(dataset, tta_num, ordered=False, do_aug=True):\n",
    "#     dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    if do_aug:\n",
    "#         dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "#         dataset = dataset.map(transform, num_parallel_calls=AUTOTUNE)\n",
    "        dataset = dataset.map(partial(process_data, img_size=512, tta_num=tta_num), num_parallel_calls=AUTOTUNE)\n",
    "        \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['image_id'] = list(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))\n",
    "\n",
    "TEST_FILENAMES = tf.io.gfile.glob(\"/kaggle/input/cassava-leaf-disease-classification/test_images/*.jpg\")\n",
    "images = tf.constant(TEST_FILENAMES)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "dataset = dataset.map(decode_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalFocalLossLabelSmoothing(tf.keras.losses.Loss):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, ls=0.1, classes=5.0):\n",
    "        super(CategoricalFocalLossLabelSmoothing, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.ls = ls\n",
    "        self.classes = classes\n",
    "        \n",
    "    def focal_loss(self, y_true, y_pred, gamma, alpha, ls, classes):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        #y_pred = y_pred + epsilon\n",
    "        #label smoothing\n",
    "        y_pred_ls = (1 - ls) * y_pred + ls / classes\n",
    "        # Clip the prediction value\n",
    "        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true*K.log(y_pred_ls)\n",
    "        # Calculate weight that consists of  modulating factor and weighting factor\n",
    "        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        return self.focal_loss(y_true, y_pred, gamma=self.gamma, alpha=self.alpha, ls=self.ls, classes=self.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "import efficientnet.keras as efn\n",
    "from efficientnet.keras import EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "models1 = tf.io.gfile.glob(\"../input/models/model*.h5\")\n",
    "models1 = [keras.models.load_model(model, custom_objects={'CategoricalFocalLossLabelSmoothing':CategoricalFocalLossLabelSmoothing}, compile=False) for model in models1]\n",
    "for model in models1:\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), loss = CategoricalFocalLossLabelSmoothing(gamma=-0.05, alpha=0.1, ls=0.3, classes=5.0), metrics=['categorical_accuracy'])\n",
    "\n",
    "models2 = tf.io.gfile.glob(\"../input/models/resnetmodel*.h5\")\n",
    "models2 = [keras.models.load_model(model) for model in models2]\n",
    "\n",
    "models1.extend(models2)\n",
    "    \n",
    "    \n",
    "for model in models1:\n",
    "    test_ds = get_test_dataset(dataset, tta_num=None, do_aug=False)\n",
    "    pred = model.predict(test_ds)\n",
    "    preds.append(pred)\n",
    "    \n",
    "tta_steps = 5\n",
    "for tta_num in range(len(tta)):\n",
    "    test_ds = get_test_dataset(dataset, tta_num=tta_num, do_aug=True)\n",
    "    for model in models1:\n",
    "        pred = model.predict(test_ds)\n",
    "        preds.append(pred)\n",
    "    \n",
    "        \n",
    "\n",
    "y_pred = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['label'] = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
